{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch00226855/CMP414765Fall2022/blob/main/Week04_MultilinearRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXhaotNQxr2w"
      },
      "source": [
        "# Week 6\n",
        "# Multilinear Regression\n",
        "\n",
        "Last time we looked at a simple linear regression model $sales = \\beta_0 + \\beta_1\\cdot\\textit{TV advertising budget}$. More generally, a linear model makes a prediction by computing a weighted sum of their input features (plus a constant).\n",
        "\n",
        "**Reading: Chapter 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81lHyTpwx0zu"
      },
      "source": [
        "## Multilinear Regression: Model Assumptions\n",
        "**Model**:\n",
        "\n",
        "$\\hat{y} = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n$\n",
        "1. $\\hat{y}$ is the predicted value.\n",
        "2. $n$ is the number of features.\n",
        "3. $x_i$ is the i-th feature value.\n",
        "4. $\\theta_j$ is the j-th model parameter (associated with $x_j$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azLxHqqUx02U"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb5RGmIdx04v"
      },
      "source": [
        "# Toy example\n",
        "columns = ['Homework', 'Midterm', 'Final']\n",
        "data = pd.DataFrame({\n",
        "    \"Homework\": [95, 70, 80, 100, 70],\n",
        "    \"Midterm\": [90, 60, 80, 80, 85],\n",
        "    \"Final\": [93, 66, 85, 60, 90]\n",
        "}, index=[\"Alice\", \"Bob\", \"Clare\", \"David\", \"Eve\"])\n",
        "\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKguV_HWx09V"
      },
      "source": [
        "In this case:\n",
        "- $x_1$ is the homework feature\n",
        "- $x_2$ is the midterm feature\n",
        "- $y$ is the final feature\n",
        "- model is: $final = \\theta_0 + \\theta_1 * homework + \\theta_2 * midterm$\n",
        "- We need to come up with values for $\\theta_0, \\theta_1, \\theta_2$ to complete the model.\n",
        "\n",
        "**Objective**: Suppose that another student Fred has Homework score 85 and Midterm score 80. What is prediction of his final exam score?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txFgiEHAx0_q"
      },
      "source": [
        "## Multilinear Regression: Vectorized form\n",
        "\n",
        "The multilinear model can also be written as:\n",
        "\n",
        "**$\\hat{y} = \\theta\\cdot\\textbf{x}$**.\n",
        "1. $\\theta = (\\theta_0, \\theta_1, ..., \\theta_n)$ is the paramter vector.\n",
        "2. $\\textbf{x} = (1, x_1, ..., x_n)$ is the feature vector.\n",
        "3. The symbol $\\cdot$ represents the inner-product of two vectors. For example, $(1, 2, 3)\\cdot (4, 5, 6) = 1\\times 4 + 2\\times 5 + 3\\times 6 = 32$.\n",
        "\n",
        "**Why is the expression $\\theta\\cdot\\textbf{x}$ equivalent to $\\theta_0 + \\theta_1x_1 + \\theta_2x_2 +\\cdots + \\theta_nx_n$?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[[\"Homework\", \"Midterm\"]]"
      ],
      "metadata": {
        "id": "ogu8cI-sUWIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8Acxyvfx1CF"
      },
      "source": [
        "# Let's apply the linear regression tool in sci-kit learn on the toy example\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(data[[\"Homework\", \"Midterm\"]], data['Final']) # You can also use data[['Final']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the prediction of Fred's final score?\n",
        "\n",
        "# Create a dataframe with Fred's records\n",
        "fred = pd.DataFrame([[85, 80]], columns=[\"Homework\", \"Midterm\"], index=['Fred'])\n",
        "# fred\n",
        "model.predict(fred)"
      ],
      "metadata": {
        "id": "gDjZUNlDU3Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model's prediction is 78. This looks safe. But how much variation the prediction has?\n",
        "# We can use model's error on the training data as an indicator\n",
        "\n",
        "data['Prediction'] = model.predict(data[['Homework', 'Midterm']])\n",
        "data"
      ],
      "metadata": {
        "id": "YyYsA6EhWWK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoD9GMG1x1Em"
      },
      "source": [
        "# Retrieve the estimated parameter values.\n",
        "print(\"theta1, theta2:\", model.coef_)\n",
        "print(\"theta0:\", model.intercept_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's create a linear model that describes the relationship between `sales` and all three ways of advertising."
      ],
      "metadata": {
        "id": "XAYjx93CYPeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.statlearning.com/s/Advertising.csv\"\n",
        "advertising = pd.read_csv(url, index_col=0)\n",
        "advertising.head()"
      ],
      "metadata": {
        "id": "yaLpN0AeYeMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proposed model: $sales = \\theta_0 + \\theta_1\\cdot TV + \\theta_2\\cdot radio + \\theta_3\\cdot newspaper$."
      ],
      "metadata": {
        "id": "DLp0zCnOY9wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "training_set, test_set = train_test_split(advertising, test_size=0.1)\n",
        "print(training_set.shape)\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "id": "l0u0JR6wZrwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = LinearRegression()\n",
        "model2.fit(training_set[['TV', 'radio', 'newspaper']], training_set['sales'])"
      ],
      "metadata": {
        "id": "LQjZLVzNYg4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_cols = ['TV', 'radio', 'newspaper']"
      ],
      "metadata": {
        "id": "fU4SjNxDa4KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The MSE of model2 on the training set\n",
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred = model2.predict(training_set[input_cols])\n",
        "training_MSE = mean_squared_error(training_set['sales'], y_pred)\n",
        "print(\"MSE on the training set:\", training_MSE)\n",
        "# This MSE is better than the MSE achieved by a simple linear regression model."
      ],
      "metadata": {
        "id": "fhAe5dXQaNtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The MSE of model2 on the test set\n",
        "y_pred = model2.predict(test_set[input_cols])\n",
        "test_MSE = mean_squared_error(test_set['sales'], y_pred)\n",
        "print(\"MSE on the training set:\", test_MSE)"
      ],
      "metadata": {
        "id": "qkfpYRzrbdMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwJG44-7x1HE"
      },
      "source": [
        "## Multilinear Regression: Cost Function\n",
        "In order to calculate the best value for each parameter, we need a **cost function** that evaluates the errors made by a give set of parameter values. Here we use the **mean squared error (MSE)** function as the cost function:\n",
        "\n",
        "$J(\\textbf{X}, \\theta) = \\frac{1}{m}\\sum_{i=1}^{m}\\big(\\theta\\cdot\\textbf{x}^{(i)} - y^{(i)}\\big)^2$\n",
        "\n",
        "Here $(\\textbf{x}^{(i)}, y^{(i)})$ represents the i-th training example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uh-Zy_vEx1JZ"
      },
      "source": [
        "# Calculate the MSE cost of the toy example for the parameter values given by sci-kit learn.\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG2rW2SNx1Lw"
      },
      "source": [
        "## Multilinear Regression: Training Algorithm 1\n",
        "The value of $\\theta$ that minimizes the cost function is given by the following **normal equation**:\n",
        "\n",
        "$\\hat{\\theta} = \\big(\\textbf{X}^T\\cdot\\textbf{X}\\big)^{-1}\\cdot\\textbf{X}^T\\cdot\\textbf{y}$.\n",
        "\n",
        "1. $\\textbf{X}$ is an $m\\times (n+1)$ matrix whose i-th row is $\\textbf{x}^{(i)}$.\n",
        "$$\\textbf{X} = \\begin{pmatrix}\n",
        "1 & x^{(1)}_1 & x^{(1)}_2 & \\cdots & x^{(1)}_n \\\\\n",
        "1 & x^{(2)}_1 & x^{(2)}_2 & \\cdots & x^{(2)}_n \\\\\n",
        "\\vdots & \\vdots &\\vdots & \\ddots & \\vdots \\\\\n",
        "1 & x^{(m)}_1 & x^{(m)}_2 & \\cdots & x^{(m)}_n \\\\\n",
        "\\end{pmatrix}$$\n",
        "2. $$\\textbf{y} = \\begin{pmatrix}y^{(1)} \\\\ \\vdots \\\\ y^{(m)}\\end{pmatrix}$$.\n",
        "3. The cost function $J(\\theta)$ also has a matrix expression\n",
        "$$J(\\theta) = \\frac{1}{m}(\\textbf{X}\\cdot\\theta - \\textbf{y})^T\\cdot (\\textbf{X}\\cdot\\theta - \\textbf{y})$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0r86Sigx1OO"
      },
      "source": [
        "# Construct matrix X using np.hstack(), np.ones()\n",
        "N = len(training_set) # N = training_set.shape[0]\n",
        "col1 = np.ones([N, 1])\n",
        "# print(col1)\n",
        "col234 = training_set[['TV', 'radio', 'newspaper']].values\n",
        "# print(col234)\n",
        "X = np.hstack([col1, col234])\n",
        "print(X[0:5, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIZZCIicx1Q7"
      },
      "source": [
        "# Construct vector y\n",
        "y = training_set[['sales']].values\n",
        "print(y[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "197CDh19x1Th"
      },
      "source": [
        "# Apply the normal equation to find theta\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.5f}\".format(x)})\n",
        "\n",
        "np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The results should be the same as the sklearn model\n",
        "print(model2.coef_)\n",
        "print(model2.intercept_)"
      ],
      "metadata": {
        "id": "SnpLfMkulFm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ezXjZlvx1WG"
      },
      "source": [
        "## Multilinear Regression: Training Algorithm 2\n",
        "The normal equation is not applicable when $\\textbf{X}^T\\cdot\\textbf{X}$ is not invertible. It happens if:\n",
        "- Several features are linearly dependent (for example, feature3 = feature1 + feature2)\n",
        "- The number of features is greater than the number of training data (for example, DNA data)\n",
        "\n",
        "When the matrix $\\textbf{X}$ is too large, the normal equation may take too long to finish since it requires a matrix multiplication.\n",
        "\n",
        "In these cases, we can use the **gradient descent** method to minimize the cost function instead.\n",
        "\n",
        "Gradient descent with one variable ideally looks like this:\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/0*fU8XFt-NCMZGAWND.\" width=\"600\">\n",
        "\n",
        "Gradient descent with two variables ideally looks like this:\n",
        "<img src=\"https://blog.paperspace.com/content/images/2019/09/F1-02.large.jpg\" width=\"600\">\n",
        "\n",
        "Gradient descent is an iterative algorithm for finding the **local minimum** of a differentiable function.\n",
        "- Choose an initial value of $\\hat{\\theta}$ and a **learning rate** $r$.\n",
        "- For each iteration $k$, do:\n",
        "$$\\hat{\\theta} \\leftarrow \\hat{\\theta} - r\\cdot\\frac{\\partial J(\\hat{\\theta})}{\\partial \\theta}.$$\n",
        "- The partial derivative of the cost function is given by\n",
        "$$\n",
        "\\frac{\\partial J(\\hat{\\theta})}{\\partial \\theta} = \\frac{2}{m}\\cdot\\textbf{X}^T\\cdot(\\textbf{X}\\cdot\\theta - \\textbf{y}).\n",
        "$$\n",
        "- **Verify the formula of partial derivative asuuming there is one input feature.**\n",
        "\n",
        "- End iteration if certain stop criteria is reached, such as:\n",
        "    - Value of $\\hat{\\theta}$ becomes stable.\n",
        "    - Certain iteration amount is reached."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clRpPwu-x1Yp"
      },
      "source": [
        "# Choose a random initial value for each parameter.\n",
        "np.random.seed(1234) \n",
        "theta = np.random.randn(4, 1)\n",
        "print(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MSE_cost(theta, X, y):\n",
        "    m = X.shape[0]\n",
        "    M = X.dot(theta) - y\n",
        "    return 1/m * M.T.dot(M)\n",
        "\n",
        "print(\"Initial cost:\", MSE_cost(theta, X, y))"
      ],
      "metadata": {
        "id": "irpo2zsSsO-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yP5gFqHx1bM"
      },
      "source": [
        "# Perform gradient descent once.\n",
        "# Choose a learning rate r\n",
        "r = 1e-5 # r = 0.00001\n",
        "\n",
        "# 1. Calculate the gradient\n",
        "m = len(training_set)\n",
        "gradient = 2/m * X.T.dot(X.dot(theta) - y)\n",
        "print(gradient)\n",
        "\n",
        "# 2. Update the parameters\n",
        "theta = theta - r * gradient\n",
        "print(theta)\n",
        "\n",
        "\n",
        "# 3. (optional) Show the MSE cost with new parameter values\n",
        "\n",
        "\n",
        "MSE_cost(theta, X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPqDCTznx1dq"
      },
      "source": [
        "# Perform gradient descent multiple times\n",
        "r = 0.00001\n",
        "np.random.seed(1234) \n",
        "theta = np.random.randn(4, 1)\n",
        "print(theta)\n",
        "\n",
        "MSEs = [] # store the intermediate MSEs\n",
        "num_iterations = 50000\n",
        "\n",
        "for i in range(num_iterations):\n",
        "\n",
        "    gradient = 2/m * X.T.dot(X.dot(theta) - y)\n",
        "    theta = theta - r * gradient\n",
        "\n",
        "    if i % 1000 == 0:\n",
        "        print(\"Iteration:\", i)\n",
        "        print(\"Gradient:\\n\", gradient)\n",
        "        print(\"New theta:\\n\", theta)\n",
        "        MSE = MSE_cost(theta, X, y)\n",
        "        print(\"New cost:\", MSE)\n",
        "        MSEs.append(MSE[0][0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the MSE with different parameter values\n",
        "\n",
        "# Optimal parameter values:\n",
        "from sklearn.metrics import mean_squared_error\n",
        "y_pred = model2.predict(training_set[[\"TV\", \"radio\", \"newspaper\"]])\n",
        "MSE = mean_squared_error(training_set['sales'], y_pred)\n",
        "print(\"Optimal MSE:\", MSE)"
      ],
      "metadata": {
        "id": "5vCm7bh1vkxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MSEs"
      ],
      "metadata": {
        "id": "gaEh3t7jw2e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sfCU6C33reK"
      },
      "source": [
        "# Plot the learning curve.\n",
        "\n",
        "plt.plot(range(len(MSEs)-2), MSEs[2:], 'b.--')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXOFqVwlx1gQ"
      },
      "source": [
        "**Discussion**\n",
        "1. Change $r$ to 0.000001 and 1. Observe the MSE curve.\n",
        "2. Do the initial parameter values matter?\n",
        "3. How to determine when to stop the iteration?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEnnJd4Qx1ii"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVWfuoUHx1lB"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVfSS1dgx1np"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}