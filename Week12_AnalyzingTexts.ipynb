{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8HoL4adzb5AsXPK0Abz+S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ch00226855/CMP414765Fall2022/blob/main/Week12_AnalyzingTexts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVw7vPwMiKe4"
      },
      "source": [
        "# Week 12\n",
        "# Analyzing Texts\n",
        "\n",
        "This notebook classifies movie reviews as positive or negative using the text of the review.\n",
        "\n",
        "We'll use the [IMDB dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) that contains the text of 50,000 movie reviews from the Internet Movie Database. These reviews are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews.\n",
        "\n",
        "**Please turn on GPU computing from the menu.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVtn0DIYozEc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(tf.config.experimental.list_physical_devices(\"GPU\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neys5y0Fo7ee"
      },
      "source": [
        "## Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-c2ZI4wxo-2h"
      },
      "source": [
        "# Split the training set into 60% and 40%, so we'll end up with 15,000 examples\n",
        "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
        "train_data, validation_data, test_data = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "    as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgstHu37pAMM"
      },
      "source": [
        "## Explore the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl6KiQaBpBqS"
      },
      "source": [
        "?train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn the training set into an iterator\n",
        "iterator = iter(train_data.batch(10))"
      ],
      "metadata": {
        "id": "N8FM7l5VY4Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXB51ZbFpDMf"
      },
      "source": [
        "# Extract the first batch of 10 reviews\n",
        "train_examples_batch, train_labels_batch = next(iterator) # The next() function returns the next item of an iterator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print a review\n",
        "print(train_examples_batch[5].numpy())"
      ],
      "metadata": {
        "id": "lgfae-7DXshC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FbgbCFtpEiq"
      },
      "source": [
        "# Display the labels of the first 10 reviews\n",
        "train_labels_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzQuawK7pHEF"
      },
      "source": [
        "## Building the Model\n",
        "Machine learning models take vectors (arrays of numbers) as input. When working with text, the first thing we must do is come up with a strategy to convert strings to numbers (or to \"vectorize\" the text) before feeding it to the model. \n",
        "\n",
        "### Attempt 1: One-Hot Encoding\n",
        "\n",
        "The **one-hot encoding** method converts each string to a vector that contains a single non-zero component (thus it is called \"one-hot\"). It is a commonly used method to convert a categorical variable to a vector.\n",
        "\n",
        "<img src=\"https://i.imgur.com/mtimFxh.png\" width=\"400\">\n",
        "\n",
        "However, one-hot encoding is a poor idea for vectorizing texts because:\n",
        "- The size of the converted vector equals to the size of the vocabulary, which is very large.\n",
        "- It does not preserve relationships between words. For example, \"no\" and \"not\" have similar meanings, but their one-hot vectors are entirely different.\n",
        "- It is not clear how one can combine all words from a sentence to form a single vector.\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/0*QMGjp-fPYpPaE3eK\" width=\"400\">\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attempt 2: The TF-IDF Approach\n",
        "\n",
        "- **Term Frequency (TF)**: How many times does each word appears?\n",
        "\n",
        "- **Document Frequency (DF)**: How many documents contains this word?\n",
        "\n",
        "- **TF-IDF metric**: TF / DF"
      ],
      "metadata": {
        "id": "MiperFtcPW4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "email1 = \"how are you are you you\"\n",
        "email2 = \"hello how you you are hello\"\n",
        "temp_data = np.array([email1, email2])\n",
        "count = CountVectorizer()\n",
        "vectors = count.fit_transform(temp_data)\n",
        "print(vectors)"
      ],
      "metadata": {
        "id": "N0blophqPlRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf = TfidfTransformer()\n",
        "vectors = tfidf.fit_transform(vectors)\n",
        "print(vectors)"
      ],
      "metadata": {
        "id": "-yb3B84dPt5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attempt 3: Use An Existing Word Embedding\n",
        "\n",
        "For this example we will use a pre-trained text embedding model from TensorFlow Hub called `gnews-swivel-20dim`, which represents text with a vector of length 20. This embedding model is trained with Swivel matrix decomposition method on 130 GB texts from Google News."
      ],
      "metadata": {
        "id": "JujOnRYOJgsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_examples_batch.shape\n",
        "vec1 = hub_layer([\"no\"]).numpy()\n",
        "print(vec1)"
      ],
      "metadata": {
        "id": "BXuLGtWkKSSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vec2 = hub_layer([\"not\"]).numpy()\n",
        "print(vec2)"
      ],
      "metadata": {
        "id": "sql6n965K-E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the cosine similarity of these vectors.\n",
        "cosine = vec1.dot(vec2.T) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "print(cosine)"
      ],
      "metadata": {
        "id": "Qha6oMJhLCrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWWRoUmwpI19"
      },
      "source": [
        "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)\n",
        "hub_layer(train_examples_batch[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples_batch[:3]"
      ],
      "metadata": {
        "id": "gKHU7YliNUrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0K0PD3npK4z"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnB-E4jrpMQH"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Wn9yPApNpO"
      },
      "source": [
        "# the fit() methods returns a collection of intermediate results, which can be useful\n",
        "# to evaluate the model\n",
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=20,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GBeeoPNpOqD"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y89oOk3TpQCl"
      },
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOoxBctJpQ4Y"
      },
      "source": [
        "# How about my own reviews?\n",
        "my_review = np.array([\"This movie is the worst action movie I have ever watched in my entire life.\",\n",
        "                      \"I really enjoyed the plot, but the lead actor didn't portray his character well.\",\n",
        "                      \"It is the most visually stunning movie in the series. The acting is outstanding too.\",\n",
        "                      \"I really like that everyone in this movie makes it crystal clear that they don't care the quality at all.\",\n",
        "                      \"There is nothing about the movie that I don't like. I wish everyone else just stop making movies since no moive can be better than this one.\"])\n",
        "model(my_review).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpvE5owlpR6t"
      },
      "source": [
        "# Extract 20 reviews from the test set\n",
        "reviews, labels = next(iter(test_data.batch(20)))\n",
        "predictions = model(reviews).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRoXFpWopUBj"
      },
      "source": [
        "labels.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzhso8YLpVTj"
      },
      "source": [
        "(predictions > 0).astype(int).reshape(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Our Own Word Embedding\n",
        "\n",
        "<a href=\"https://www.tensorflow.org/text/guide/word_embeddings\">TensorFlow tutorial on work embedding</a>"
      ],
      "metadata": {
        "id": "IvHAPLgmNxdT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQ4O_rbwOsXY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}